{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !pip install nltk\n",
    "#!python -m spacy download en_core_web_sm\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"dataset\\user_reviews.csv\")\n",
    "# # df.info()\n",
    "\n",
    "# # Remove rows with NaN values\n",
    "# df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# # for getting the app with the highest number of reviews (Bowmasters)\"\"\"\n",
    "# max_participants_count = df['App'].value_counts()\n",
    "# print(max_participants_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #filter data for a selected app\n",
    "# filter = df[(df['App'] =='Bowmasters')]\n",
    "\n",
    "# #retrieve 2 columns for sentiment analysis\n",
    "# df_copy = ['App', 'Translated_Review']\n",
    "# df = filter[df_copy].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SpaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to clean a single review\n",
    "def clean(text):\n",
    "    # Parse the review using SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Lemmatize and remove stopwords\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    \n",
    "    #remove punctuations and extra whitespaces\n",
    "    clean_text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "def batch_data_cleaning(df, review_column):\n",
    "    # Apply clean_review function to each review in the specified column\n",
    "    df[review_column] = df[review_column].apply(clean)\n",
    "\n",
    "    return df\n",
    "\n",
    "# cleaned_df = batch_data_cleaning(df, 'Translated_Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_df.to_csv('dataset/preprocessed_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('dataset/preprocessed_dataset.csv')\n",
    "# df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# # determine the discrete emotion label based on compound score of the sentiment result\n",
    "# def discrete_emotion_labelling(sentiment_score):\n",
    "\n",
    "#     if sentiment_score >= 0.5:\n",
    "#         return \"Happy\"\n",
    "#     elif sentiment_score <= -0.5:\n",
    "#         return \"Angry\"\n",
    "#     elif sentiment_score < 0 and sentiment_score >= -0.5:\n",
    "#         return \"Sad\"\n",
    "#     else:\n",
    "#         return \"Neutral\"\n",
    "\n",
    "# df['scores'] = df['Translated_Review'].apply(lambda review: analyzer.polarity_scores(review))\n",
    "# df['compound_score'] = df['scores'].apply(lambda score: score['compound'])\n",
    "\n",
    "# # Labelling\n",
    "# df['label'] = df['compound_score'].apply(lambda score: discrete_emotion_labelling(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('dataset/labelled_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML (Support Vector Classifier) algorithm training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classify the emotion based on the sentiment of the review'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"classify the emotion based on the sentiment of the review\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7424525781458723\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.66      0.47      0.55       711\n",
      "       Happy       0.85      0.87      0.86      3475\n",
      "     Neutral       0.67      0.79      0.72      2362\n",
      "         Sad       0.53      0.36      0.43       938\n",
      "\n",
      "    accuracy                           0.74      7486\n",
      "   macro avg       0.68      0.62      0.64      7486\n",
      "weighted avg       0.73      0.74      0.73      7486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Translated_Review'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', max_iter=1000000)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Happy\n",
      "[2] Sad\n",
      "[3] Neutral\n",
      "[4] Happy\n",
      "[5] Angry\n"
     ]
    }
   ],
   "source": [
    "new_reviews = [\n",
    "    \"I  used to love this app, but the recent update ruined everything. It crashes constantly and I've lost all my data. It's heartbreaking to see something I relied on so much become so unreliable.\",\n",
    "    \"it's so annoying and trash, the app button didn't even work, and the customer support doesn't exist!\",\n",
    "    \"This is bullshit.\",\n",
    "    \"Wow, this app is a game-changer! It's fast, intuitive, and packed with useful features. I've never been so impressed with an app before. It's made my life so much easier and I can't stop recommending it to everyone I know.\",\n",
    "    \"Bullshit, what a waste of time. It's so useless, fuck this shit\",\n",
    "]\n",
    "\n",
    "def predict(review):\n",
    "    # Preprocess the review text\n",
    "    new_review_tfidf = tfidf_vectorizer.transform([clean(review)])\n",
    "    \n",
    "    # Predict the emotion of the review\n",
    "    predicted_category = svm_classifier.predict(new_review_tfidf)[0]\n",
    "\n",
    "    return predicted_category\n",
    "\n",
    "for i, review in enumerate(new_reviews):\n",
    "    print(f\"[{i+1}] {predict(review)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
